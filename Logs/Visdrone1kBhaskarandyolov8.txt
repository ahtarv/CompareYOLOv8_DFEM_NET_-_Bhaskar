
arrow_upwardarrow_downwarddelete

    write_file(os.path.join(base, "dfem_net.yaml"), MODEL_YAML)
    
    # Write Runner
    script = RUNNER_SCRIPT_TEMPLATE.replace("{MODEL_NAME}", "DFEM-Net")
    script = script.replace("{YAML_FILE}", "dfem_net.yaml")
    script = script.replace("{RUN_NAME}", "DFEM_Run")
    script = script.replace("{EPOCHS}", str(EPOCHS))
    # Pure Python implementation is stable with AMP
    script = script.replace("{AMP}", "True") 
    write_file(os.path.join(base, "train_dfem.py"), script)


def main():
    print("--- 1. Setting up Workspaces ---")
    setup_bhaskar()
    setup_dfem()
    print("Workspaces created: Bhaskar_Experiment/, DFEM_Experiment/")
    
    # --- DATASET PRUNING ---
    print(f"--- âœ‚ï¸ STARTING DATASET REDUCTION (Target: {TARGET_TRAIN} Train / {TARGET_VAL} Val) ---")
    
    # Force download if needed
    visdrone_path = os.path.join(os.getcwd(), 'datasets', 'VisDrone')
    parent_visdrone_path = os.path.join(os.getcwd(), '..', 'datasets', 'VisDrone')
    
    if not os.path.exists(visdrone_path) and not os.path.exists(parent_visdrone_path):
         # Try to trigger download via dummy train
         print("Dataset not found. Triggering download...")
         try:
             model = YOLO('yolov8n.yaml')
             # Just checking if we can trigger download
             model.train(data='VisDrone.yaml', epochs=1, imgsz=640, batch=1, name='setup_download')
         except:
             pass

    # Locate dataset
    base_path = None
    if os.path.exists(visdrone_path):
        base_path = visdrone_path
    elif os.path.exists(parent_visdrone_path):
        base_path = parent_visdrone_path
    else:
        # Fallback assumption
        base_path = 'datasets/VisDrone'

    if base_path and os.path.exists(base_path):
         # Check structure. YOLO format usually images/train
         if os.path.exists(os.path.join(base_path, 'images', 'train')):
             shrink_dataset(os.path.join(base_path, 'images', 'train'), os.path.join(base_path, 'labels', 'train'), TARGET_TRAIN)
             shrink_dataset(os.path.join(base_path, 'images', 'val'),   os.path.join(base_path, 'labels', 'val'),   TARGET_VAL)
         else:
             print(f"Warning: Standard 'images/train' structure not found in {base_path}. Attempting to search recursively or skipping.")
    else:
         print(f"Warning: Could not locate dataset at {base_path}. Skipping reduction.")

    
    print("\n--- 2. Training YOLOv8 (Benchmark) ---")
    try:
        model = YOLO('yolov8n.yaml')
        # Using VisDrone.yaml (Ultralytics handles download automatically)
        model.train(data='VisDrone.yaml', epochs=EPOCHS, imgsz=640, project='Kaggle_Benchmark_VisDrone', name='YOLOv8_Run')

    except Exception as e:
        print(f"YOLOv8 Training Failed: {e}")

    print("\n--- 3. Training BhaskarNet ---")
    try:
        # Run in subprocess to isolate modules
        subprocess.run([sys.executable, "train_bhaskar.py"], check=True, cwd="Bhaskar_Experiment")
    except Exception as e:
        print(f"BhaskarNet Training Failed: {e}")

    print("\n--- 4. Training DFEM-Net ---")
    try:
        # Run in subprocess to isolate modules
        subprocess.run([sys.executable, "train_dfem.py"], check=True, cwd="DFEM_Experiment")
    except Exception as e:
        print(f"DFEM-Net Training Failed: {e}")
        
    print("\nAll experiments complete. Check 'Kaggle_Benchmark_VisDrone' folder for results.")

if __name__ == "__main__":
    main()

Ultralytics not found. Installing...
Collecting ultralytics
  Downloading ultralytics-8.4.14-py3-none-any.whl.metadata (39 kB)
Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)
Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)
Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)
Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)
Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)
Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.5)
Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.15.3)
Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)
Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)
Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)
Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)
Collecting ultralytics-thop>=2.0.18 (from ultralytics)
  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)
Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)
Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)
Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)
Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)
Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (26.0rc2)
Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)
Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)
Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)
Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)
Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.6.3)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2026.1.4)
Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.3)
Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)
Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)
Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)
Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)
Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.10.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)
Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)
Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)
Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)
Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)
Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)
Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)
Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)
Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)
Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)
Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)
Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)
Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)
Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)
Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)
Downloading ultralytics-8.4.14-py3-none-any.whl (1.2 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.2/1.2 MB 32.0 MB/s eta 0:00:00
Downloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)
Installing collected packages: ultralytics-thop, ultralytics
Successfully installed ultralytics-8.4.14 ultralytics-thop-2.0.18
Creating new Ultralytics Settings v0.0.6 file âœ… 
View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'
Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.
--- 1. Setting up Workspaces ---
Workspaces created: Bhaskar_Experiment/, DFEM_Experiment/
--- âœ‚ï¸ STARTING DATASET REDUCTION (Target: 1000 Train / 200 Val) ---
Dataset not found. Triggering download...
Ultralytics 8.4.14 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)
engine/trainer: agnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=VisDrone.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.yaml, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=setup_download, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/runs/detect/setup_download, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None

WARNING âš ï¸ Dataset 'VisDrone.yaml' images not found, missing path '/kaggle/working/datasets/VisDrone/images/val'
Downloading 3 file(s) with 4 threads to /kaggle/working/datasets/VisDrone...
Downloading https://ultralytics.com/assets/VisDrone2019-DET-val.zip to '/kaggle/working/datasets/VisDrone/VisDrone2019-DET-val.zip': 100% â”â”â”â”â”â”â”â”â”â”â”â” 77.9MB 59.8MB/s 1.3s1.3s<0.1s17.1ss<2.5ss
Unzipping /kaggle/working/datasets/VisDrone/VisDrone2019-DET-val.zip to /kaggle/working/datasets/VisDrone/VisDrone2019-DET-val...: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1099/1099 2.1Kfiles/s 0.5s0.0s.8s<12.4s1.8s
Downloading https://ultralytics.com/assets/VisDrone2019-DET-test-dev.zip to '/kaggle/working/datasets/VisDrone/VisDrone2019-DET-test-dev.zip': 100% â”â”â”â”â”â”â”â”â”â”â”â” 296.8MB 72.5MB/s 4.1s 4.1s<0.1s
Unzipping /kaggle/working/datasets/VisDrone/VisDrone2019-DET-test-dev.zip to /kaggle/working/datasets/VisDrone/VisDrone2019-DET-test-dev...: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3223/3223 1.9Kfiles/s 1.7s7s2s
Downloading https://ultralytics.com/assets/VisDrone2019-DET-train.zip to '/kaggle/working/datasets/VisDrone/VisDrone2019-DET-train.zip': 100% â”â”â”â”â”â”â”â”â”â”â”â” 1.4GB 46.2MB/s 32.0s2.0s<0.0s14.2s
Unzipping /kaggle/working/datasets/VisDrone/VisDrone2019-DET-train.zip to /kaggle/working/datasets/VisDrone/VisDrone2019-DET-train...: 100% â”â”â”â”â”â”â”â”â”â”â”â” 12945/12945 2.2Kfiles/s 5.8ss<0.1s
Converting train: â”â”â”â”â”â”â”â”â”â”â”â” 6471 2.5Kit/s 2.5s
Converting val: â”â”â”â”â”â”â”â”â”â”â”â” 548 1.5Kit/s 0.2ss
Converting test: â”â”â”â”â”â”â”â”â”â”â”â” 1610 2.3Kit/s 0.6s
Dataset download success âœ… (42.0s), saved to /kaggle/working/datasets

Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 42.8MB/s 0.0s
Overriding model.yaml nc=80 with nc=10

                   from  n    params  module                                       arguments                     
  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 
  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                
  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             
  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                
  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             
  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               
  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           
  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              
  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           
  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 
 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          
 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 
 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          
 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  
 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                
 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 
 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              
 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 
 22        [15, 18, 21]  1    753262  ultralytics.nn.modules.head.Detect           [10, 16, None, [64, 128, 256]]
YOLOv8n summary: 130 layers, 3,012,798 parameters, 3,012,782 gradients, 8.2 GFLOPs

Freezing layer 'model.22.dfl.conv.weight'
AMP: running Automatic Mixed Precision (AMP) checks...
Downloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.3MB 152.3MB/s 0.0s
AMP: checks passed âœ…
train: Fast image access âœ… (ping: 0.0Â±0.0 ms, read: 2892.7Â±376.4 MB/s, size: 260.7 KB)
train: Scanning /kaggle/working/datasets/VisDrone/labels/train... 6471 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 6471/6471 1.2Kit/s 5.2s<0.0s
train: /kaggle/working/datasets/VisDrone/images/train/0000137_02220_d_0000163.jpg: 1 duplicate labels removed
train: /kaggle/working/datasets/VisDrone/images/train/0000140_00118_d_0000002.jpg: 1 duplicate labels removed
train: /kaggle/working/datasets/VisDrone/images/train/9999945_00000_d_0000114.jpg: 1 duplicate labels removed
train: /kaggle/working/datasets/VisDrone/images/train/9999987_00000_d_0000049.jpg: 1 duplicate labels removed
train: New cache created: /kaggle/working/datasets/VisDrone/labels/train.cache
albumentations: Blur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))
val: Fast image access âœ… (ping: 0.0Â±0.0 ms, read: 986.6Â±523.5 MB/s, size: 142.1 KB)
val: Scanning /kaggle/working/datasets/VisDrone/labels/val... 548 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 548/548 906.4it/s 0.6s0.2s
val: New cache created: /kaggle/working/datasets/VisDrone/labels/val.cache
optimizer: 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... 
optimizer: AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)
Plotting labels to /kaggle/working/runs/detect/setup_download/labels.jpg... 
Image sizes 640 train, 640 val
Using 4 dataloader workers
Logging results to /kaggle/working/runs/detect/setup_download
Starting training for 1 epochs...

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
        1/1      0.57G      3.926      4.248      2.474         54        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 6471/6471 11.7it/s 9:11<0.2s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 274/274 24.0it/s 11.4s<0.0s
                   all        548      38759     0.0306     0.0811     0.0269    0.00933

1 epochs completed in 0.157 hours.
Optimizer stripped from /kaggle/working/runs/detect/setup_download/weights/last.pt, 6.2MB
Optimizer stripped from /kaggle/working/runs/detect/setup_download/weights/best.pt, 6.2MB

Validating /kaggle/working/runs/detect/setup_download/weights/best.pt...
Ultralytics 8.4.14 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)
YOLOv8n summary (fused): 73 layers, 3,007,598 parameters, 0 gradients, 8.1 GFLOPs
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 274/274 43.6it/s 6.3s0.1s
                   all        548      38759     0.0308     0.0811      0.027    0.00935
            pedestrian        520       8844     0.0257     0.0457     0.0164    0.00491
                people        482       5125     0.0828      0.033     0.0443     0.0149
               bicycle        364       1287          0          0          0          0
                   car        515      14064     0.0504      0.431      0.124      0.042
                   van        421       1975     0.0202      0.187     0.0172    0.00668
                 truck        266        750     0.0138     0.0547    0.00746    0.00333
              tricycle        337       1045     0.0455    0.00191      0.023    0.00919
       awning-tricycle        220        532          0          0          0          0
                   bus        131        251    0.00272      0.012    0.00138   0.000645
                 motor        485       4886      0.067     0.0452     0.0365     0.0118
Speed: 0.2ms preprocess, 4.0ms inference, 0.0ms loss, 2.5ms postprocess per image
Results saved to /kaggle/working/runs/detect/setup_download
ğŸ“‰ Reducing /kaggle/working/datasets/VisDrone/images/train from 6471 -> 1000 images...
ğŸ—‘ï¸ Deleted 5471 pairs. New size: 1000 images.
ğŸ“‰ Reducing /kaggle/working/datasets/VisDrone/images/val from 548 -> 200 images...
ğŸ—‘ï¸ Deleted 348 pairs. New size: 200 images.

--- 2. Training YOLOv8 (Benchmark) ---
Ultralytics 8.4.14 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)
engine/trainer: agnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=VisDrone.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.yaml, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=YOLOv8_Run, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=Kaggle_Benchmark_VisDrone, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/runs/detect/Kaggle_Benchmark_VisDrone/YOLOv8_Run, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None
Overriding model.yaml nc=80 with nc=10

                   from  n    params  module                                       arguments                     
  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 
  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                
  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             
  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                
  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             
  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               
  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           
  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              
  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           
  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 
 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          
 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 
 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          
 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  
 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                
 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 
 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              
 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 
 22        [15, 18, 21]  1    753262  ultralytics.nn.modules.head.Detect           [10, 16, None, [64, 128, 256]]
YOLOv8n summary: 130 layers, 3,012,798 parameters, 3,012,782 gradients, 8.2 GFLOPs

Freezing layer 'model.22.dfl.conv.weight'
AMP: running Automatic Mixed Precision (AMP) checks...
AMP: checks passed âœ…
train: Fast image access âœ… (ping: 0.0Â±0.0 ms, read: 2483.4Â±790.6 MB/s, size: 153.4 KB)
train: Scanning /kaggle/working/datasets/VisDrone/labels/train... 1000 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1000/1000 1.3Kit/s 0.8s1ss
train: /kaggle/working/datasets/VisDrone/images/train/9999945_00000_d_0000114.jpg: 1 duplicate labels removed
train: New cache created: /kaggle/working/datasets/VisDrone/labels/train.cache
albumentations: Blur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))
val: Fast image access âœ… (ping: 0.0Â±0.0 ms, read: 857.8Â±533.7 MB/s, size: 202.8 KB)
val: Scanning /kaggle/working/datasets/VisDrone/labels/val... 200 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 200/200 526.5it/s 0.4s0.1s
val: New cache created: /kaggle/working/datasets/VisDrone/labels/val.cache
optimizer: 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... 
optimizer: AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)
Plotting labels to /kaggle/working/runs/detect/Kaggle_Benchmark_VisDrone/YOLOv8_Run/labels.jpg... 
Image sizes 640 train, 640 val
Using 4 dataloader workers
Logging results to /kaggle/working/runs/detect/Kaggle_Benchmark_VisDrone/YOLOv8_Run
Starting training for 10 epochs...
Closing dataloader mosaic
albumentations: Blur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       1/10      5.23G      5.103      5.602      4.205        442        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.2it/s 19.4s0.3s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 5.4it/s 1.3s0.2s
                   all        200      13295          0          0          0          0

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       2/10      6.02G      4.193      4.074      3.294        421        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 4.9it/s 12.9s0.2s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 5.9it/s 1.2s0.2s
                   all        200      13295          0          0          0          0

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       3/10      6.02G      3.725       3.44      2.608        475        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 4.9it/s 12.8s0.2s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 4.6it/s 1.5s0.3s
                   all        200      13295      0.512     0.0166     0.0052    0.00153

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       4/10      6.02G      3.465      3.105      2.263        377        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 5.0it/s 12.6s0.2s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 3.8it/s 1.9s0.3s
                   all        200      13295      0.528      0.018     0.0183    0.00458

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       5/10      6.03G      3.319      2.961      2.091        338        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 5.0it/s 12.7s0.2s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 4.4it/s 1.6s0.3s
                   all        200      13295      0.022     0.0576     0.0194    0.00658

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       6/10      6.04G      3.238      2.828      1.958        449        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 5.0it/s 12.7s0.2s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 4.4it/s 1.6s0.3s
                   all        200      13295     0.0272     0.0742     0.0256    0.00887

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       7/10      6.04G      3.133      2.764      1.874        503        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 5.0it/s 12.6s0.2s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 4.6it/s 1.5s0.3s
                   all        200      13295      0.027     0.0907     0.0304     0.0106

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       8/10      6.04G      3.089      2.693       1.83        401        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 5.0it/s 12.6s0.2s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 4.7it/s 1.5s0.3s
                   all        200      13295     0.0325      0.104     0.0354     0.0129

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       9/10      6.05G      3.032      2.648      1.793        336        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 5.0it/s 12.7s0.2s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 4.5it/s 1.6s0.3s
                   all        200      13295     0.0353     0.0956     0.0382     0.0141

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
      10/10      6.05G      3.016      2.611      1.746        582        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 5.0it/s 12.6s0.2s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 4.2it/s 1.7s0.3s
                   all        200      13295     0.0419      0.103     0.0445     0.0165

10 epochs completed in 0.043 hours.
Optimizer stripped from /kaggle/working/runs/detect/Kaggle_Benchmark_VisDrone/YOLOv8_Run/weights/last.pt, 6.2MB
Optimizer stripped from /kaggle/working/runs/detect/Kaggle_Benchmark_VisDrone/YOLOv8_Run/weights/best.pt, 6.2MB

Validating /kaggle/working/runs/detect/Kaggle_Benchmark_VisDrone/YOLOv8_Run/weights/best.pt...
Ultralytics 8.4.14 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)
YOLOv8n summary (fused): 73 layers, 3,007,598 parameters, 0 gradients, 8.1 GFLOPs
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 1.6it/s 4.4s0.4s
                   all        200      13295     0.0418      0.103     0.0443     0.0164
            pedestrian        190       2955     0.0342     0.0491     0.0254    0.00694
                people        176       1750       0.13     0.0469     0.0809     0.0259
               bicycle        123        419      0.013    0.00239    0.00894    0.00358
                   car        185       4906     0.0564      0.516      0.204     0.0797
                   van        155        735     0.0239       0.22     0.0229    0.00999
                 truck        100        283     0.0162     0.0636    0.00942    0.00394
              tricycle        121        355      0.023    0.00563     0.0116    0.00465
       awning-tricycle         80        174     0.0294    0.00575     0.0171     0.0103
                   bus         47         85     0.0178     0.0353    0.00991    0.00198
                 motor        175       1633     0.0736     0.0857     0.0526     0.0166
Speed: 0.1ms preprocess, 1.2ms inference, 0.0ms loss, 3.7ms postprocess per image
Results saved to /kaggle/working/runs/detect/Kaggle_Benchmark_VisDrone/YOLOv8_Run

--- 3. Training BhaskarNet ---
--- Setting up BhaskarNet ---
Modules imported successfully.
Modules registered.
--- Starting Training for BhaskarNet ---
Ultralytics 8.4.14 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)
engine/trainer: agnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=VisDrone.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=bhaskar_net.yaml, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=Bhaskar_Run, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=Kaggle_Benchmark_VisDrone, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/Bhaskar_Experiment/runs/detect/Kaggle_Benchmark_VisDrone/Bhaskar_Run, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None
Overriding model.yaml nc=80 with nc=10

                   from  n    params  module                                       arguments                     
  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 
  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                
  2                  -1  3     71904  TuaBottleneck.TuaBottleneck                  [32, 32, True]                
  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                
  4                  -1  6    570240  TuaBottleneck.TuaBottleneck                  [64, 64, True]                
  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               
  6                  -1  6   2270976  TuaBottleneck.TuaBottleneck                  [128, 128, True]              
  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              
  8                  -1  3   4531968  TuaBottleneck.TuaBottleneck                  [256, 256, True]              
  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 
 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          
 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 12                  -1  3    312576  ultralytics.nn.modules.block.C2f             [384, 128, 3]                 
 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          
 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 15                  -1  3     78464  ultralytics.nn.modules.block.C2f             [192, 64, 3]                  
 16                  12  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          
 17                   9  1         0  torch.nn.modules.upsampling.Upsample         [None, 4, 'nearest']          
 18        [15, 16, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 19                  18  1     41280  saclseq.Scalseq                              [64, 128, 256]                
 20                  -1  1     12448  zoomcat.Zoomcat                              [64]                          
 21         [15, 12, 9]  1    753262  ultralytics.nn.modules.head.Detect           [10, 16, None, [64, 128, 256]]
bhaskar_net summary: 369 layers, 9,200,830 parameters, 9,200,814 gradients, 28.8 GFLOPs

Freezing layer 'model.21.dfl.conv.weight'
AMP: running Automatic Mixed Precision (AMP) checks...
Downloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.3MB 176.6MB/s 0.0s
AMP: checks passed âœ…
train: Fast image access âœ… (ping: 0.0Â±0.0 ms, read: 3022.4Â±904.1 MB/s, size: 165.0 KB)
train: Scanning /kaggle/working/datasets/VisDrone/labels/train.cache... 1000 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1000/1000 199.7Mit/s 0.0s
train: /kaggle/working/datasets/VisDrone/images/train/9999945_00000_d_0000114.jpg: 1 duplicate labels removed
albumentations: Blur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))
val: Fast image access âœ… (ping: 0.0Â±0.0 ms, read: 1244.9Â±883.6 MB/s, size: 191.2 KB)
val: Scanning /kaggle/working/datasets/VisDrone/labels/val.cache... 200 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 200/200 6.9Mit/s 0.0s
optimizer: 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... 
optimizer: AdamW(lr=0.000714, momentum=0.9) with parameter groups 108 weight(decay=0.0), 176 weight(decay=0.0005), 211 bias(decay=0.0)
Plotting labels to /kaggle/working/Bhaskar_Experiment/runs/detect/Kaggle_Benchmark_VisDrone/Bhaskar_Run/labels.jpg... 
Image sizes 640 train, 640 val
Using 4 dataloader workers
Logging results to /kaggle/working/Bhaskar_Experiment/runs/detect/Kaggle_Benchmark_VisDrone/Bhaskar_Run
Starting training for 10 epochs...
Closing dataloader mosaic
albumentations: Blur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       1/10      1.98G      4.948      6.155      3.762        322        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 250/250 1.2s/it 5:03<1.2s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 7.9it/s 3.2s0.1s
                   all        200      13295      0.606    0.00759    0.00208   0.000524

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       2/10      2.21G      3.825      3.695      2.609        204        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 250/250 1.2s/it 4:57<1.2s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 7.5it/s 3.3s0.1s
                   all        200      13295      0.315     0.0256     0.0103     0.0035

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       3/10      2.24G      3.482      3.254       2.16        216        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 250/250 1.2s/it 4:57<1.2s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 7.6it/s 3.3s0.1s
                   all        200      13295      0.334     0.0513     0.0219    0.00717

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       4/10      2.27G      3.291      3.039      1.951        198        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 250/250 1.2s/it 4:57<1.2s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 7.5it/s 3.4s0.1s
                   all        200      13295     0.0258     0.0854     0.0272     0.0094

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       5/10       2.3G      3.195      2.892      1.845        124        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 250/250 1.2s/it 4:57<1.2s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 7.7it/s 3.2s0.1s
                   all        200      13295     0.0278      0.103     0.0315     0.0118

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       6/10       2.3G      3.074      2.791      1.771        140        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 250/250 1.2s/it 4:57<1.2s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 7.5it/s 3.3s0.1s
                   all        200      13295     0.0311      0.107     0.0358     0.0143

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       7/10       2.3G      3.023      2.759      1.713        194        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 250/250 1.2s/it 4:57<1.2s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 7.7it/s 3.2s0.1s
                   all        200      13295     0.0439      0.118     0.0429     0.0181

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       8/10       2.3G      2.965      2.679      1.665        195        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 250/250 1.2s/it 4:57<1.2s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 7.7it/s 3.3s0.1s
                   all        200      13295     0.0395      0.121     0.0464     0.0196

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       9/10       2.3G      2.921      2.634      1.658        166        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 250/250 1.2s/it 4:57<1.2s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 7.8it/s 3.2s0.1s
                   all        200      13295     0.0592      0.114     0.0504     0.0212

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
      10/10      2.33G      2.889      2.605       1.63        183        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 250/250 1.2s/it 4:57<1.2s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 7.7it/s 3.3s0.1s
                   all        200      13295      0.046      0.126     0.0504     0.0214

10 epochs completed in 0.838 hours.
Optimizer stripped from /kaggle/working/Bhaskar_Experiment/runs/detect/Kaggle_Benchmark_VisDrone/Bhaskar_Run/weights/last.pt, 18.8MB
Optimizer stripped from /kaggle/working/Bhaskar_Experiment/runs/detect/Kaggle_Benchmark_VisDrone/Bhaskar_Run/weights/best.pt, 18.8MB

Validating /kaggle/working/Bhaskar_Experiment/runs/detect/Kaggle_Benchmark_VisDrone/Bhaskar_Run/weights/best.pt...
Ultralytics 8.4.14 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)
bhaskar_net summary: 334 layers, 9,198,222 parameters, 0 gradients, 28.7 GFLOPs
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 5.8it/s 4.3s0.1s
                   all        200      13295     0.0461      0.126     0.0504     0.0215
            pedestrian        190       2955     0.0415     0.0657     0.0286    0.00901
                people        176       1750      0.166     0.0663     0.0944     0.0336
               bicycle        123        419          0          0          0          0
                   car        185       4906     0.0681      0.542      0.259       0.12
                   van        155        735     0.0333      0.294     0.0357     0.0182
                 truck        100        283      0.019      0.131     0.0103    0.00501
              tricycle        121        355          0          0          0          0
       awning-tricycle         80        174     0.0341    0.00575    0.00786    0.00629
                   bus         47         85    0.00545     0.0353    0.00297    0.00141
                 motor        175       1633     0.0935       0.12      0.065     0.0215
Speed: 0.2ms preprocess, 9.6ms inference, 0.0ms loss, 5.4ms postprocess per image
Results saved to /kaggle/working/Bhaskar_Experiment/runs/detect/Kaggle_Benchmark_VisDrone/Bhaskar_Run
Training for BhaskarNet complete.

--- 4. Training DFEM-Net ---
--- Setting up DFEM-Net ---
Modules imported successfully.
Modules registered.
--- Starting Training for DFEM-Net ---
Ultralytics 8.4.14 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)
engine/trainer: agnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=VisDrone.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=dfem_net.yaml, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=DFEM_Run, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=Kaggle_Benchmark_VisDrone, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/DFEM_Experiment/runs/detect/Kaggle_Benchmark_VisDrone/DFEM_Run, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None
Overriding model.yaml nc=80 with nc=10

                   from  n    params  module                                       arguments                     
  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 
  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                
  2                  -1  3    102924  TuaBottleneck.TuaBottleneck                  [32, 32, True]                
  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                
  4                  -1  6    694104  TuaBottleneck.TuaBottleneck                  [64, 64, True]                
  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               
  6                  -1  6   2518488  TuaBottleneck.TuaBottleneck                  [128, 128, True]              
  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              
  8                  -1  3   4779372  TuaBottleneck.TuaBottleneck                  [256, 256, True]              
  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 
 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          
 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 12                  -1  3    312576  ultralytics.nn.modules.block.C2f             [384, 128, 3]                 
 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          
 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 15                  -1  3     78464  ultralytics.nn.modules.block.C2f             [192, 64, 3]                  
 16                  12  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          
 17                   9  1         0  torch.nn.modules.upsampling.Upsample         [None, 4, 'nearest']          
 18        [15, 16, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 19                  18  1     41280  saclseq.Scalseq                              [64, 128, 256]                
 20                  -1  1     12448  zoomcat.Zoomcat                              [64]                          
 21         [15, 12, 9]  1    753262  ultralytics.nn.modules.head.Detect           [10, 16, None, [64, 128, 256]]
dfem_net summary: 297 layers, 9,850,630 parameters, 9,850,614 gradients, 15.9 GFLOPs

Freezing layer 'model.21.dfl.conv.weight'
AMP: running Automatic Mixed Precision (AMP) checks...
Downloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.3MB 48.3MB/s 0.1s.1s<0.1s
AMP: checks passed âœ…
train: Fast image access âœ… (ping: 0.0Â±0.0 ms, read: 2855.8Â±868.5 MB/s, size: 165.0 KB)
train: Scanning /kaggle/working/datasets/VisDrone/labels/train.cache... 1000 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1000/1000 199.7Mit/s 0.0s
train: /kaggle/working/datasets/VisDrone/images/train/9999945_00000_d_0000114.jpg: 1 duplicate labels removed
albumentations: Blur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))
val: Fast image access âœ… (ping: 0.0Â±0.0 ms, read: 1401.7Â±928.2 MB/s, size: 191.2 KB)
val: Scanning /kaggle/working/datasets/VisDrone/labels/val.cache... 200 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 200/200 6.8Mit/s 0.0s
optimizer: 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... 
optimizer: AdamW(lr=0.000714, momentum=0.9) with parameter groups 72 weight(decay=0.0), 212 weight(decay=0.0005), 247 bias(decay=0.0)
Plotting labels to /kaggle/working/DFEM_Experiment/runs/detect/Kaggle_Benchmark_VisDrone/DFEM_Run/labels.jpg... 
Image sizes 640 train, 640 val
Using 4 dataloader workers
Logging results to /kaggle/working/DFEM_Experiment/runs/detect/Kaggle_Benchmark_VisDrone/DFEM_Run
Starting training for 10 epochs...
Closing dataloader mosaic
albumentations: Blur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       1/10      2.98G      5.053      6.502       3.83        322        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 250/250 1.5it/s 2:50<0.7s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/25  0.1s
Traceback (most recent call last):
  File "/kaggle/working/DFEM_Experiment/train_dfem.py", line 63, in <module>
    train()
  File "/kaggle/working/DFEM_Experiment/train_dfem.py", line 51, in train
    results = model.train(
              ^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py", line 774, in train
    self.trainer.train()
  File "/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py", line 244, in train
    self._do_train()
  File "/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py", line 518, in _do_train
    self.metrics, self.fitness = self.validate()
                                 ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py", line 746, in validate
    metrics = self.validator(self)
              ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/ultralytics/engine/validator.py", line 217, in __call__
    preds = model(batch["img"], augment=augment)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/ultralytics/nn/tasks.py", line 142, in forward
    return self.predict(x, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/ultralytics/nn/tasks.py", line 159, in predict
    return self._predict_once(x, profile, visualize, embed)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/ultralytics/nn/tasks.py", line 181, in _predict_once
    x = m(x)  # run
        ^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py", line 244, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/kaggle/working/DFEM_Experiment/TuaBottleneck.py", line 33, in forward
    y= self.attn(y)
       ^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/kaggle/working/DFEM_Experiment/TuaAttention.py", line 30, in forward
    x_dcn = self.dcn1(x_act)
            ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/kaggle/working/DFEM_Experiment/dfem_parts.py", line 117, in forward
    sampled_features = F.grid_sample(x, sampling_locations_flat, align_corners=True, padding_mode='zeros')
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py", line 5104, in grid_sample
    return torch.grid_sampler(input, grid, mode_enum, padding_mode_enum, align_corners)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected tensor for argument #1 'input' to have the same type as tensor for argument #2 'grid'; but type torch.cuda.HalfTensor does not equal torch.cuda.FloatTensor (while checking arguments for cudnn_grid_sampler_forward)